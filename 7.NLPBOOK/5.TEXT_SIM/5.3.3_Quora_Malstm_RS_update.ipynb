{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial global var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 미리 Global 변수를 지정하자. 파일 명, 파일 위치, 디렉토리 등이 있다.\n",
    "\n",
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
    "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
    "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
    "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
    "\n",
    "## 학습에 필요한 파라메터들에 대해서 지정하는 부분이다.\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 50\n",
    "HIDDEN = 64\n",
    "BUFFER_SIZE = 2048\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "EMBEDDING_DIM = 128\n",
    "MAX_SEQ_LEN = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 불러오는 부분이다. 효과적인 데이터 불러오기를 위해, 미리 넘파이 형태로 저장시킨 데이터를 로드한다.\n",
    "\n",
    "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "with open(DATA_IN_PATH + NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    prepro_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q1_data])\n",
    "q2_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q2_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 나누어 저장하자. sklearn의 train_test_split을 사용하면 유용하다. 하지만, 쿼라 데이터의 경우는\n",
    "## 입력이 1개가 아니라 2개이다. 따라서, np.stack을 사용하여 두개를 하나로 쌓은다음 활용하여 분류한다.\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "\n",
    "train_Q1 = train_X[:,0]\n",
    "train_Q2 = train_X[:,1]\n",
    "test_Q1 = test_X[:,0]\n",
    "test_Q2 = test_X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(base, hypothesis, labels):\n",
    "    features = {\"base\": base, \"hypothesis\": hypothesis}\n",
    "    return features, labels\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_Q1, train_Q2, train_y))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_Q1))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_Q1, test_Q2, test_y))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Malstm(features, labels, mode, params):\n",
    "        \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    labels = tf.to_float(tf.reshape(labels, [-1,1]))\n",
    "\n",
    "    def basic_bilstm_network(inputs, name, reuse=tf.AUTO_REUSE):\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "            lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "            lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "            outputs, state = tf.nn.bidirectional_dynamic_rnn(cell_fw = lstm_fw_cell,\n",
    "                                                              cell_bw = lstm_bw_cell,\n",
    "                                                              inputs = inputs,\n",
    "                                                              dtype = tf.float32)\n",
    "            concat = tf.concat([outputs[0], outputs[1]], axis=2)\n",
    "            final_state = tf.keras.layers.Dense(128)(concat[:,-1,:])\n",
    "\n",
    "        return final_state\n",
    "        \n",
    "    embedding = tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    \n",
    "    base_embedded_matrix = embedding(features['base'])\n",
    "    hypothesis_embedded_matrix = embedding(features['hypothesis'])\n",
    "\n",
    "    base_embedded_matrix = tf.keras.layers.Dropout(0.2)(base_embedded_matrix)\n",
    "    hypothesis_embedded_matrix = tf.keras.layers.Dropout(0.2)(hypothesis_embedded_matrix)    \n",
    "    \n",
    "    base_sementic_matrix = basic_bilstm_network(base_embedded_matrix, 'base')\n",
    "    hypothesis_sementic_matrix = basic_bilstm_network(hypothesis_embedded_matrix, 'hypothesis')\n",
    "    \n",
    "#     merged_matrix = tf.concat([base_sementic_matrix, hypothesis_sementic_matrix], -1)\n",
    "\n",
    "    logit_layer = K.exp(-K.sum(K.abs(base_sementic_matrix -  hypothesis_sementic_matrix), axis=1, keepdims=True))\n",
    "                \n",
    "    if PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  predictions={\n",
    "                      'prob':tf.nn.sigmoid(logit_layer)\n",
    "                  })\n",
    "    \n",
    "    loss =tf.losses.sigmoid_cross_entropy(labels, logit_layer)\n",
    "    \n",
    "    if EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.nn.sigmoid(logit_layer))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  eval_metric_ops= eval_metric_ops,\n",
    "                  loss=loss)\n",
    "\n",
    "    elif TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  train_op=train_op,\n",
    "                  loss=loss)\n",
    "\n",
    "    \n",
    "params = {'embed_init': tf.random_uniform_initializer(-1.0, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x21278ccf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./data_out/checkpoint/model.ckpt-11\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 11 into ./data_out/checkpoint/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931473, step = 12\n",
      "INFO:tensorflow:global_step/sec: 0.518635\n",
      "INFO:tensorflow:loss = 0.6931473, step = 17 (9.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.59284\n",
      "INFO:tensorflow:loss = 0.6931473, step = 22 (0.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83557\n",
      "INFO:tensorflow:loss = 0.6931473, step = 27 (0.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.82325\n",
      "INFO:tensorflow:loss = 0.6931473, step = 32 (0.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.90618\n",
      "INFO:tensorflow:loss = 0.6931473, step = 37 (1.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.9895\n",
      "INFO:tensorflow:loss = 0.6931473, step = 42 (1.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56363\n",
      "INFO:tensorflow:loss = 0.6931473, step = 47 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.5766\n",
      "INFO:tensorflow:loss = 0.6931473, step = 52 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.48696\n",
      "INFO:tensorflow:loss = 0.6931473, step = 57 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.9513\n",
      "INFO:tensorflow:loss = 0.6931473, step = 62 (0.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02652\n",
      "INFO:tensorflow:loss = 0.6931473, step = 67 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25005\n",
      "INFO:tensorflow:loss = 0.6931473, step = 72 (0.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16314\n",
      "INFO:tensorflow:loss = 0.6931473, step = 77 (0.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.73804\n",
      "INFO:tensorflow:loss = 0.6931473, step = 82 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.85029\n",
      "INFO:tensorflow:loss = 0.6931473, step = 87 (0.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.84553\n",
      "INFO:tensorflow:loss = 0.6931473, step = 92 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03854\n",
      "INFO:tensorflow:loss = 0.6931473, step = 97 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99601\n",
      "INFO:tensorflow:loss = 0.6931473, step = 102 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95586\n",
      "INFO:tensorflow:loss = 0.6931473, step = 107 (0.840 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 111 into ./data_out/checkpoint/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.75412\n",
      "INFO:tensorflow:loss = 0.6931473, step = 112 (2.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93101\n",
      "INFO:tensorflow:loss = 0.6931473, step = 117 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.82666\n",
      "INFO:tensorflow:loss = 0.6931473, step = 122 (0.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.54611\n",
      "INFO:tensorflow:loss = 0.6931473, step = 127 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06244\n",
      "INFO:tensorflow:loss = 0.6931473, step = 132 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.77434\n",
      "INFO:tensorflow:loss = 0.6931473, step = 137 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45409\n",
      "INFO:tensorflow:loss = 0.6931473, step = 142 (0.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.47762\n",
      "INFO:tensorflow:loss = 0.6931473, step = 147 (0.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.77074\n",
      "INFO:tensorflow:loss = 0.6931473, step = 152 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.56846\n",
      "INFO:tensorflow:loss = 0.6931473, step = 157 (0.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.81684\n",
      "INFO:tensorflow:loss = 0.6931473, step = 162 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.77111\n",
      "INFO:tensorflow:loss = 0.6931473, step = 167 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.89499\n",
      "INFO:tensorflow:loss = 0.6931473, step = 172 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.89741\n",
      "INFO:tensorflow:loss = 0.6931473, step = 177 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02813\n",
      "INFO:tensorflow:loss = 0.6931473, step = 182 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.92617\n",
      "INFO:tensorflow:loss = 0.6931473, step = 187 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.70266\n",
      "INFO:tensorflow:loss = 0.6931473, step = 192 (0.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02476\n",
      "INFO:tensorflow:loss = 0.6931473, step = 197 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.76685\n",
      "INFO:tensorflow:loss = 0.6931473, step = 202 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.85606\n",
      "INFO:tensorflow:loss = 0.6931473, step = 207 (0.854 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 211 into ./data_out/checkpoint/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.79241\n",
      "INFO:tensorflow:loss = 0.6931473, step = 212 (2.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97608\n",
      "INFO:tensorflow:loss = 0.6931473, step = 217 (0.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13817\n",
      "INFO:tensorflow:loss = 0.6931473, step = 222 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33422\n",
      "INFO:tensorflow:loss = 0.6931473, step = 227 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11154\n",
      "INFO:tensorflow:loss = 0.6931473, step = 232 (0.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.56776\n",
      "INFO:tensorflow:loss = 0.6931473, step = 237 (0.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12407\n",
      "INFO:tensorflow:loss = 0.6931473, step = 242 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04022\n",
      "INFO:tensorflow:loss = 0.6931473, step = 247 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99127\n",
      "INFO:tensorflow:loss = 0.6931473, step = 252 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01152\n",
      "INFO:tensorflow:loss = 0.6931473, step = 257 (0.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95393\n",
      "INFO:tensorflow:loss = 0.6931473, step = 262 (0.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03785\n",
      "INFO:tensorflow:loss = 0.6931473, step = 267 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13823\n",
      "INFO:tensorflow:loss = 0.6931473, step = 272 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1348\n",
      "INFO:tensorflow:loss = 0.6931473, step = 277 (0.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.90867\n",
      "INFO:tensorflow:loss = 0.6931473, step = 282 (0.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06938\n",
      "INFO:tensorflow:loss = 0.6931473, step = 287 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83375\n",
      "INFO:tensorflow:loss = 0.6931473, step = 292 (0.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.34568\n",
      "INFO:tensorflow:loss = 0.6931473, step = 297 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.36765\n",
      "INFO:tensorflow:loss = 0.6931473, step = 302 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07253\n",
      "INFO:tensorflow:loss = 0.6931473, step = 307 (0.823 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 311 into ./data_out/checkpoint/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.74061\n",
      "INFO:tensorflow:loss = 0.6931473, step = 312 (2.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.90442\n",
      "INFO:tensorflow:loss = 0.6931473, step = 317 (0.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97274\n",
      "INFO:tensorflow:loss = 0.6931473, step = 322 (0.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28883\n",
      "INFO:tensorflow:loss = 0.6931473, step = 327 (0.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02029\n",
      "INFO:tensorflow:loss = 0.6931473, step = 332 (0.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96768\n",
      "INFO:tensorflow:loss = 0.6931473, step = 337 (0.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.81197\n",
      "INFO:tensorflow:loss = 0.6931473, step = 342 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98008\n",
      "INFO:tensorflow:loss = 0.6931473, step = 347 (0.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53765\n",
      "INFO:tensorflow:loss = 0.6931473, step = 352 (0.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.27565\n",
      "INFO:tensorflow:loss = 0.6931473, step = 357 (0.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.27477\n",
      "INFO:tensorflow:loss = 0.6931473, step = 362 (0.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.16531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6931473, step = 367 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.54431\n",
      "INFO:tensorflow:loss = 0.6931473, step = 372 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.13704\n",
      "INFO:tensorflow:loss = 0.6931473, step = 377 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96956\n",
      "INFO:tensorflow:loss = 0.6931473, step = 382 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.6133\n",
      "INFO:tensorflow:loss = 0.6931473, step = 387 (0.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94129\n",
      "INFO:tensorflow:loss = 0.6931473, step = 392 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06086\n",
      "INFO:tensorflow:loss = 0.6931473, step = 397 (0.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.91909\n",
      "INFO:tensorflow:loss = 0.6931473, step = 402 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.74108\n",
      "INFO:tensorflow:loss = 0.6931473, step = 407 (0.870 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 411 into ./data_out/checkpoint/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.75367\n",
      "INFO:tensorflow:loss = 0.6931473, step = 412 (2.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93581\n",
      "INFO:tensorflow:loss = 0.6931473, step = 417 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.63492\n",
      "INFO:tensorflow:loss = 0.6931473, step = 422 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.63583\n",
      "INFO:tensorflow:loss = 0.6931473, step = 427 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.70639\n",
      "INFO:tensorflow:loss = 0.6931473, step = 432 (0.876 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-99f3b85b7145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdssm_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMalstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_OUT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdssm_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1060\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_dir = os.path.join(os.getcwd(), DATA_OUT_PATH + \"/checkpoint/\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "config_tf = tf.estimator.RunConfig()\n",
    "config_tf._save_checkpoints_steps = 100\n",
    "config_tf._save_checkpoints_secs = None\n",
    "config_tf._keep_checkpoint_max =  2\n",
    "config_tf._log_step_count_steps = 5\n",
    "\n",
    "dssm_est = tf.estimator.Estimator(Malstm, model_dir=DATA_OUT_PATH + 'checkpoint', config=config_tf, params=params)\n",
    "dssm_est.train(train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Q1_DATA_FILE = 'test_q1.npy'\n",
    "TEST_Q2_DATA_FILE = 'test_q2.npy'\n",
    "\n",
    "test_q1_data = np.load(open(DATA_IN_PATH + TEST_Q1_DATA_FILE, 'rb'))\n",
    "test_q2_data = np.load(open(DATA_IN_PATH + TEST_Q2_DATA_FILE, 'rb'))\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"q\":test_q1_data, \n",
    "                                                         \"sim_q\":test_q2_data}, \n",
    "                                                      shuffle=False)\n",
    "\n",
    "predictions = np.array([p['prob'] for p in est.predict(input_fn=predict_input_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DEFAULT_PATH='~/.kaggle/competitions/quora-question-pairs/'\n",
    "\n",
    "test = pd.read_csv(DEFAULT_PATH + \"test.csv\", encoding='utf-8')\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={\"test_id\":test[\"test_id\"], \"is_duplicate\": list(predictions)} )\n",
    "output.to_csv(DATA_OUT_PATH + \"rnn_predict.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# validation_monitor = tf.contrib\n",
    "\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)\n",
    "\n",
    "# train_spec = tf.estimator.TrainSpec(train_input_fn)\n",
    "# eval_spec = tf.estimator.EvalSpec(test_input_fn)\n",
    "\n",
    "dssm_est = tf.estimator.Estimator(Malstm, model_dir=model_dir, config=config_tf, params=params)\n",
    "dssm_est.train(train_input_fn, steps=EPOCH)\n",
    "\n",
    "# tf.estimator.train_and_evaluate(dssm_est, train_spec, eval_spec)\n",
    "\n",
    "# For prediction or extract values\n",
    "# prediction = est.predict(eval_input_fn)\n",
    "\n",
    "# for i, p in enumerate(prediction):\n",
    "#     print(i, p['sim_q_sem'])\n",
    "\n",
    "time_end = datetime.now()\n",
    "\n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
