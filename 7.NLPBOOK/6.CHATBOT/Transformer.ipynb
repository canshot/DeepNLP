{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(vocab, pad, start, end, unk):\n",
    "    \n",
    "    t2i = {'<PAD>': pad, '<BOS>': start, '<EOS>': end, '<UNK>': unk}\n",
    "    i2t = {pad: '<PAD>', start: '<BOS>', end: '<EOS>', unk: '<UNK>'}\n",
    "    \n",
    "    for word, idx in vocab.items():\n",
    "        t2i[word] = idx + 3\n",
    "        i2t[idx + 3] = word\n",
    "        \n",
    "    return t2i, i2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    '''\n",
    "    Load numpy data\n",
    "    \n",
    "    Args:\n",
    "        inputs: json data type, key => title, value => poem\n",
    "    \n",
    "    \n",
    "    Return:\n",
    "        inputs\n",
    "        vocab\n",
    "    '''\n",
    "    \n",
    "    pad_token = 0 # <PAD>\n",
    "    start_token = 1 # <BOS>\n",
    "    end_token = 2 # <EOS>\n",
    "    unk_token = 3 #<UNK>\n",
    "    \n",
    "    \n",
    "    data = json.load(open(file_path, 'r'))\n",
    "    data_list = []\n",
    "    all_sentences = []\n",
    "    \n",
    "    for poem in data.values():\n",
    "        data_list.append(poem)\n",
    "        all_sentences.extend(poem)\n",
    "    \n",
    "    source = []\n",
    "    target = []\n",
    "    \n",
    "    for item in data_list:\n",
    "        source.extend(item[:-1])\n",
    "        target.extend(item[1:])\n",
    "        \n",
    "    max_len = int(round(np.array([len(x.split(' ')) for x in all_sentences]).mean()))\n",
    "    \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_sentences)\n",
    "    source = tokenizer.texts_to_sequences(source)\n",
    "    target = tokenizer.texts_to_sequences(target)\n",
    "    \n",
    "    assert len(source) == len(target)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        source[i] = np.hstack(([start_token], np.add(source[i][:max_len], 3), [end_token]))\n",
    "        target[i] = np.hstack(([start_token], np.add(target[i][:max_len], 3), [end_token]))    \n",
    "            \n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(source, maxlen=max_len + 2, padding = 'post')\n",
    "    labels = tf.keras.preprocessing.sequence.pad_sequences(target, maxlen=max_len + 2, padding = 'post')\n",
    "    \n",
    "    t2i, i2t = make_vocab(tokenizer.word_index, pad_token, start_token, end_token, unk_token)\n",
    "    \n",
    "    \n",
    "    return inputs, labels, t2i, i2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(inputs, labels):\n",
    "    \n",
    "    encoder_inputs = inputs[:,1:]\n",
    "    decoder_inputs = labels[:, :-1]\n",
    "    decoder_outputs = labels[:, 1:]\n",
    "    \n",
    "    return encoder_inputs, decoder_inputs, decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losd_numpy_array(path):\n",
    "    return np.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(sentence_len, model_dim, dtype = tf.float32):\n",
    "    '''\n",
    "    Positional Encoding\n",
    "    paper: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    arg\n",
    "        sentence_len: integer.\n",
    "        model_dim: integer. dimension used by model\n",
    "        dtype: tensorflow data type Default is 'tf.float32'\n",
    "    \n",
    "    return\n",
    "        positional_2d: shape is [sentence_len, model_dim]\n",
    "    '''\n",
    "    \n",
    "    positional_1d = np.array([pos/10000**(2*i/model_dim) for pos in range(sentence_len) for i in range(model_dim)])\n",
    "    # for even number\n",
    "    positional_1d[::2] = np.sin(positional_1d[::2])\n",
    "    positional_1d[1::2] = np.cos(positional_1d[1::2])\n",
    "    \n",
    "    positional_2d = positional_1d.reshape([sentence_len, model_dim])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return positional_2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(queries, \n",
    "                            keys,\n",
    "                            values,\n",
    "                            k_dim,\n",
    "                            v_dim,\n",
    "                            num_heads = 8,\n",
    "                            num_units = None, \n",
    "                            drop_out = 0, \n",
    "                            is_train = True, \n",
    "                            scope = \"multi_head_attention\", \n",
    "                            reuse = None, \n",
    "                            masked = False):\n",
    "    \n",
    "    '''\n",
    "    Multi head Attention\n",
    "    \n",
    "    Input\n",
    "    queries => [BS x sentence len x d_model]\n",
    "    keys => [BS x sentence len x d_model]\n",
    "    value => [BS x sentence len x d_moel]\n",
    "    num_heads => number of head\n",
    "    k_dim => dimension of k\n",
    "    v_dim => dimension of v\n",
    "    '''\n",
    "    \n",
    "    assert k_dim % num_heads == 0, 'Dimension can\\'t devided by number of head' \n",
    "    assert v_dim % num_heads == 0, 'Dimension can\\'t devided by number of head' \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        \n",
    "        d_model = queries.shape.as_list()[-1]\n",
    "        batch_size = queries.shape.as_list()[0]\n",
    "        sentence_len = queries.shape.as_list()[1]\n",
    "        \n",
    "        '''\n",
    "        Q => [ BS x sentence len x k_dim ]\n",
    "        K => [ BS x sentence len x k_dim ]\n",
    "        V => [ BS x sentence len x v_dim ]\n",
    "        '''\n",
    "        Q = tf.keras.layers.Dense(units = k_dim)(queries)\n",
    "        K = tf.keras.layers.Dense(units = k_dim)(keys)\n",
    "        V = tf.keras.layers.Dense(units = v_dim)(values)\n",
    "        \n",
    "        '''\n",
    "        Masking 추가 필요\n",
    "        '''\n",
    "        \n",
    "        k_dim_i = k_dim // num_heads \n",
    "        v_dim_i = v_dim // num_heads\n",
    "        \n",
    "        Q_i = tf.stack(tf.split(value = Q, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (k_dim/num_head)]\n",
    "        K_i = tf.stack(tf.split(value = K, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (k_dim/num_head)]\n",
    "        V_i = tf.stack(tf.split(value = V, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (v_dim/num_head)]\n",
    "        \n",
    "        Q_K = tf.matmul(Q_i, tf.transpose(K_i, [0,1,3,2])) / (K_i.shape.as_list()[-1] ** 0.5) # [num_head x BS x sentence_len x sentence_len]\n",
    "\n",
    "        \n",
    "        #if masked:\n",
    "        #    output_like_softmax = tf.ones_like(Q_K[0, 0, :, :])\n",
    "        #    lower_triangle = tf.linalg.LinearOperatorLowerTriangular(output_like_softmax).to_dense()\n",
    "        #    masks = tf.tile(tf.expand_dims(tf.expand_dims(lower_triangle, 0), 0), [Q_K.shape.as_list()[0], Q_K.shape.as_list()[1], 1, 1])\n",
    "        #    pad = tf.ones_like(masks) * -(2**32 +1)\n",
    "        #    Q_K = tf.where(tf.equal(masks, 0), pad, Q_K)\n",
    "        \n",
    "        if masked:\n",
    "            masks = tf.linalg.LinearOperatorLowerTriangular(Q_K).to_dense()\n",
    "            pad = tf.ones_like(masks) * -(2**32 +1)\n",
    "            Q_K = tf.where(tf.equal(masks, 0), pad, Q_K)\n",
    "        \n",
    "        Q_K_softmax = tf.nn.softmax(Q_K) # [num_head x BS x sentence_len x sentence_len]\n",
    "        outputs = tf.matmul(Q_K_softmax, V_i) # [num_head x BS x sentence len x (v_dim/num_head)]\n",
    "            \n",
    "        outputs = tf.transpose(outputs,[1,2,0,3])\n",
    "        shape_outputs = outputs.get_shape().as_list() # [?, 7, 8, 64]\n",
    "        outputs = tf.reshape(outputs, shape = [-1, shape_outputs[1], shape_outputs[2] * shape_outputs[3]])\n",
    "        outputs = tf.keras.layers.Dense(units = d_model)(outputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_normalize(x, f_x, scpoe = \"add_and_normalize\"):\n",
    "    return tf.contrib.layers.layer_norm(tf.add(x,f_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_layer(inputs, w1_dim, w2_dim, scope = \"feed_forward_layer\"):\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        x = tf.keras.layers.Dense(units=w1_dim, activation=tf.nn.relu)(inputs)\n",
    "        out = tf.keras.layers.Dense(units=w2_dim)(x)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_layer(inputs, num_filter1, num_filter2, scope = \"conv_1d_layer\"):\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        x = tf.keras.layers.Conv1D(filters = num_filter1, kernel_size = 1, activation = tf.nn.relu)(inputs)\n",
    "        out = tf.keras.layers.Conv1D(filters = num_filter2, kernel_size = 2)(inputs)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(encoder_inputs, num_layers, k_dim, v_dim, num_heads, w1_dim = None, w2_dim = None,\n",
    "            dropout_rate = 0.2, use_conv = False):\n",
    "    \n",
    "    ## is_train 추가필요, 우선 어디 사용되는지 확인 필요\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        encoder_inputs: embeded and encoded inputs, shape => [BS x sentence_len x model_dim]\n",
    "        num_layers: integer, number of layers\n",
    "        k_dim: integer, dimension of keys and queries\n",
    "        v_dim: integer, dimension of values\n",
    "        num_heads: integer, number of head\n",
    "        w1_dim: integer, number of units in first feed forward layer\n",
    "        w_2dim: integer, number of units in second feed forward layer. It must be same with dimension of model\n",
    "        dropout_rate: float, it must be in [0, 1]. Dropout rate\n",
    "        embedding_matrix: matrix with shape [vocab_size x model_dim], It's used when model use pre-train embedding vector\n",
    "        vocab_size: integer. If it doesn't use pre-train embedding. then have to put vocab_size\n",
    "        embedding_dimension: integer. If it doesn't use pre-train embedding. then have to put embedding_dimension\n",
    "        use_conv: Bool, If True, use conv-1d, instead of feed forward layer\n",
    "        \n",
    "    Returns:\n",
    "        encoder_outputs: matrix with shape [BS x sentence_len x model_dim]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"encoder\", reuse = False):\n",
    "        \n",
    "        model_dim = encoder_inputs.shape.as_list()[2]\n",
    "        \n",
    "        encoder_inputs = tf.keras.layers.Dropout(rate = dropout_rate)(encoder_inputs)\n",
    "        \n",
    "        if w1_dim is None:\n",
    "            w1_dim = model_dim * 4\n",
    "        if w2_dim is None:\n",
    "            w2_dim = model_dim\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            with tf.variable_scope(\"encoder_{}-layer\".format(i)):\n",
    "                encoder_inputs_attention = multi_head_attention(queries = encoder_inputs,\n",
    "                                                                 keys = encoder_inputs,\n",
    "                                                                 values =  encoder_inputs,\n",
    "                                                                 k_dim = k_dim,\n",
    "                                                                 v_dim = v_dim,\n",
    "                                                                 num_heads = num_heads,\n",
    "                                                                 drop_out = dropout_rate,\n",
    "                                                                 masked = True)\n",
    "                encoder_inputs = add_and_normalize(x = encoder_inputs, f_x = encoder_inputs_attention)\n",
    "                \n",
    "                if use_conv:\n",
    "                    encoder_inputs_forward = conv_1d_layer(inputs = encoder_inputs, num_filter1 = w1_dim, num_filter2 = w2_dim)\n",
    "                else:\n",
    "                    encoder_inputs_forward = feed_forward_layer(inputs = encoder_inputs, w1_dim = w1_dim, w2_dim = w2_dim)\n",
    "                encoder_inputs = add_and_normalize(x = encoder_inputs, f_x = encoder_inputs_forward)\n",
    "            \n",
    "                    \n",
    "        encoder_ouputs = encoder_inputs        \n",
    "        \n",
    "        return encoder_ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(encoder_outputs, decoder_inputs, num_layers, k_dim, v_dim, num_heads, w1_dim = None, w2_dim = None,\n",
    "            dropout_rate = 0.2, use_conv = False):\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        encoder_inputs: embeded and encoded inputs, shape => [BS x sentence_len x model_dim]\n",
    "        num_layers: integer, number of layers\n",
    "        k_dim: integer, dimension of keys and queries\n",
    "        v_dim: integer, dimension of values\n",
    "        num_heads: integer, number of head\n",
    "        w1_dim: integer, number of units in first feed forward layer\n",
    "        w_2dim: integer, number of units in second feed forward layer. It must be same with dimension of model\n",
    "        dropout_rate: float, it must be in [0, 1]. Dropout rate\n",
    "        embedding_matrix: matrix with shape [vocab_size x model_dim], It's used when model use pre-train embedding vector\n",
    "        vocab_size: integer. If it doesn't use pre-train embedding. then have to put vocab_size\n",
    "        embedding_dimension: integer. If it doesn't use pre-train embedding. then have to put embedding_dimension\n",
    "        use_conv: Bool, If True, use conv-1d, instead of feed forward layer\n",
    "        \n",
    "    Returns:\n",
    "        encoder_outputs: matrix with shape [BS x sentence_len x model_dim]\n",
    "    '''\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\", reuse = False):\n",
    "        \n",
    "        model_dim = decoder_inputs.shape.as_list()[2]\n",
    "        \n",
    "        decoder_inputs = tf.keras.layers.Dropout(rate = dropout_rate)(decoder_inputs)\n",
    "        \n",
    "        if w1_dim is None:\n",
    "            w1_dim = model_dim * 2\n",
    "        if w2_dim is None:\n",
    "            w2_dim = model_dim\n",
    "        \n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            with tf.variable_scope(\"decoder_{}-layer\".format(i)):\n",
    "                decoder_self_attention = multi_head_attention(queries = decoder_inputs,\n",
    "                                                                 keys = decoder_inputs,\n",
    "                                                                 values =  decoder_inputs,\n",
    "                                                                 k_dim = k_dim,\n",
    "                                                                 v_dim = v_dim,\n",
    "                                                                 num_heads = num_heads,\n",
    "                                                                 drop_out = dropout_rate,\n",
    "                                                                 masked = True)\n",
    "                \n",
    "                decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_self_attention)\n",
    "                \n",
    "                decoder_attention = multi_head_attention(queries = encoder_outputs,\n",
    "                                                            keys = encoder_outputs,\n",
    "                                                            values = decoder_inputs,\n",
    "                                                            k_dim = k_dim,\n",
    "                                                            v_dim = v_dim,\n",
    "                                                            num_heads = num_heads,\n",
    "                                                            drop_out = dropout_rate,\n",
    "                                                            masked = True)\n",
    "                \n",
    "                decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_attention)\n",
    "                \n",
    "                if use_conv:\n",
    "                    decoder_inputs_forward = conv_1d_layer(inputs = decoder_inputs, num_filter1 = w1_dim, num_filter2 = w2_dim)\n",
    "                else:\n",
    "                    decoder_inputs_forward = feed_forward_layer(inputs = decoder_inputs, w1_dim = w1_dim, w2_dim = w2_dim)\n",
    "                \n",
    "                decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_inputs_forward)\n",
    "    \n",
    "        decoder_outputs = decoder_inputs\n",
    "        \n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, mode, params):\n",
    "    \n",
    "    embedding_matrix = params['embedding_matrix']\n",
    "    VOCAB_SIZE = params['vocab_size']\n",
    "    EMBEDDING_DIMENSION = params['embedding_dimension']\n",
    "    NUM_LAYERS = params['num_layers']\n",
    "    K_DIM = params['k_dim']\n",
    "    V_DIM = params['v_dim']\n",
    "    NUM_HEADS = params['num_heads']\n",
    "    W1_DIM = params['w1_dim']\n",
    "    W2_DIM = params['w2_dim']\n",
    "    DROPOUT_RATE = params['dropout_rate']\n",
    "    USE_CONV = params['use_conv']\n",
    "    SENTENCE_LEN = params['sentence_len']\n",
    "    LEARNING_RATE = params['learning_rate']\n",
    "    \n",
    "    \n",
    "    encoder_inputs = features['encoder_inputs']\n",
    "    decoder_inputs = features['decoder_inputs']\n",
    "    labels = features['decoder_labels']\n",
    "    \n",
    "    batch_size = tf.shape(encoder_inputs)[0]\n",
    "    \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    \n",
    "    if embedding_matrix is None:\n",
    "        embedding_matrix = tf.get_variable(name = 'embedding_matrix',\n",
    "                                           dtype=tf.float32,\n",
    "                                           shape=[VOCAB_SIZE, EMBEDDING_DIMENSION],\n",
    "                                           initializer = tf.contrib.layers.xavier_initializer())\n",
    "    # if zero_pad:\n",
    "    # \n",
    "    \n",
    "    encoder_inputs = tf.nn.embedding_lookup(ids = encoder_inputs, params = embedding_matrix)\n",
    "    decoder_inputs = tf.nn.embedding_lookup(ids = decoder_inputs, params = embedding_matrix)\n",
    "    \n",
    "    encoder_inputs = tf.add(encoder_inputs,\n",
    "                            positional_encoding(sentence_len = SENTENCE_LEN, model_dim = EMBEDDING_DIMENSION, dtype = tf.float32))\n",
    "    decoder_inputs = tf.add(decoder_inputs,\n",
    "                            positional_encoding(sentence_len = SENTENCE_LEN, model_dim = EMBEDDING_DIMENSION, dtype = tf.float32))\n",
    "    \n",
    "    #embedding함수 지우고 dropout 추가필요\n",
    "    \n",
    "    encoder_outputs = encoder(encoder_inputs = encoder_inputs,\n",
    "                              num_layers = NUM_LAYERS,\n",
    "                              k_dim = K_DIM,\n",
    "                              v_dim = V_DIM,\n",
    "                              num_heads = NUM_HEADS,\n",
    "                              w1_dim = W1_DIM,\n",
    "                              w2_dim = W2_DIM,\n",
    "                              dropout_rate = DROPOUT_RATE,\n",
    "                              use_conv = USE_CONV)\n",
    "    \n",
    "    decoder_outputs = decoder(encoder_outputs = encoder_outputs,\n",
    "                              decoder_inputs = decoder_inputs,\n",
    "                              num_layers = NUM_LAYERS,\n",
    "                              k_dim = K_DIM,\n",
    "                              v_dim = V_DIM,\n",
    "                              num_heads = NUM_HEADS,\n",
    "                              w1_dim = W1_DIM,\n",
    "                              w2_dim = W2_DIM,\n",
    "                              dropout_rate = DROPOUT_RATE,\n",
    "                              use_conv = USE_CONV)\n",
    "    \n",
    "    embedding_matrix_tile = tf.tile(tf.expand_dims(embedding_matrix, 0), [batch_size, 1, 1])\n",
    "    \n",
    "    linear_outputs = tf.matmul(decoder_outputs, embedding_matrix_tile, transpose_b = True) # [BS x sen_len x vocab_size]\n",
    "    \n",
    "    prob_outputs = tf.nn.softmax(linear_outputs)\n",
    "    token_outputs = tf.argmax(prob_outputs, axis = -1)\n",
    "    if PREDICT:\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = token_outputs)\n",
    "        \n",
    "    mask_zero = 1 - tf.cast(tf.equal(labels, 0),dtype=tf.float32)\n",
    "    mask_end = 1 - tf.cast(tf.equal(labels, 2), dtype=tf.float32)\n",
    "    labels_one_hot = tf.one_hot(indices = labels, depth = VOCAB_SIZE, dtype = tf.float32) # [BS, senxlen, vocab_size]\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels = labels_one_hot, logits = linear_outputs)\n",
    "    loss = loss * mask_zero\n",
    "    loss = loss * mask_end\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "        train_optimizer = optimizer.minimize(loss, global_step  = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_optimizer)\n",
    "    \n",
    "\n",
    "    # label smoothing 기법 추가필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_decoder_inputs(input_token, output_token, idx):\n",
    "    \n",
    "    '''\n",
    "    idx: 1->6\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # input_token, output_token, idx\n",
    "    # [1,0,0,0,0,0,0], X, [1 , 32, X, X, X, X]\n",
    "    # [1,32,0,0,0,0,0], [1, 32, 77, X, X, X, X], 1\n",
    "    # [1,32,77,0,0,0,0], []\n",
    "    # [1,32,77,5,0,0,0]\n",
    "    # [1,32,77,5,39,0,0]\n",
    "    # [1,32,77,5,39,8,0]\n",
    "    \n",
    "    batch_size = input_token.shape.as_list()[0]\n",
    "    max_len = input_token.shape.as_list()[1]\n",
    "    \n",
    "    left = tf.slice(input_token, [0,0], [batch_size, idx])\n",
    "    right = tf.slice(output_token [0, idx], [batch_size, 1])\n",
    "    zero = tf.zeros_like(input_token)\n",
    "    zero_slice = tf.slice(zero, [0, idx + 1], [batch_size, max_len - (idx + 1)])\n",
    "    \n",
    "    new_input = tf.concat((left,right,zero_slice), axis=1)\n",
    "    \n",
    "    return new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './poem_data.json'\n",
    "\n",
    "inputs, labels, t2i, i2t = load_data(PATH)\n",
    "encoder_inputs, decoder_inputs, decoder_labels = prepare_data(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_fn(X, Y, Z):\n",
    "    features = {'encoder_inputs': X, 'decoder_inputs': Y, 'decoder_labels': Z}\n",
    "    return features\n",
    "\n",
    "def train_data():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((encoder_inputs, decoder_inputs, decoder_labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(encoder_inputs))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCH)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './check_point', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000189A16D4EF0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = './check_point'\n",
    "params = {'embedding_matrix': None,\n",
    "          'vocab_size': len(i2t),\n",
    "          'embedding_dimension': 512,\n",
    "          'num_layers': 6,\n",
    "          'k_dim': 512,\n",
    "          'v_dim': 512,\n",
    "          'num_heads': 8,\n",
    "          'w1_dim': None,\n",
    "          'w2_dim': None,\n",
    "          'dropout_rate': 0.2,\n",
    "          'use_conv': False,\n",
    "          'sentence_len': encoder_inputs.shape[1],\n",
    "          'learning_rate': 0.001}\n",
    "\n",
    "est = tf.estimator.Estimator(model, model_dir=MODEL_DIR, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./check_point\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5.336877, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 96 into ./check_point\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.020566.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x189a16d4cf8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCH = 2\n",
    "\n",
    "est.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_encoder_inputs, pred_decoder_inputs, pred_decoder_outputs = np.array([encoder_inputs[38]]), np.array([decoder_inputs[38]]), np.array([decoder_inputs[38]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_input_fn():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((pred_encoder_inputs, pred_decoder_inputs, pred_decoder_outputs))\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./check_point\\model.ckpt-96\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict = [p for p in est.predict(input_fn = pred_input_fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 5, 5, 5, 5, 5, 5], dtype=int64)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "764//16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
