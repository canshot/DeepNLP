{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(vocab, pad, start, end, unk):\n",
    "    \n",
    "    t2i = {'<PAD>': pad, '<BOS>': start, '<EOS>': end, '<UNK>': unk}\n",
    "    i2t = {pad: '<PAD>', start: '<BOS>', end: '<EOS>', unk: '<UNK>'}\n",
    "    \n",
    "    for word, idx in vocab.items():\n",
    "        t2i[word] = idx + 3\n",
    "        i2t[idx + 3] = word\n",
    "        \n",
    "    return t2i, i2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    '''\n",
    "    Load numpy data\n",
    "    \n",
    "    Args:\n",
    "        inputs: json data type, key => title, value => poem\n",
    "    \n",
    "    \n",
    "    Return:\n",
    "        inputs\n",
    "        vocab\n",
    "    '''\n",
    "    \n",
    "    pad_token = 0 # <PAD>\n",
    "    start_token = 1 # <BOS>\n",
    "    end_token = 2 # <EOS>\n",
    "    unk_token = 3 #<UNK>\n",
    "    \n",
    "    \n",
    "    data = json.load(open(file_path, 'r'))\n",
    "    data_list = []\n",
    "    all_sentences = []\n",
    "    \n",
    "    for poem in data.values():\n",
    "        data_list.append(poem)\n",
    "        all_sentences.extend(poem)\n",
    "    \n",
    "    source = []\n",
    "    target = []\n",
    "    \n",
    "    for item in data_list:\n",
    "        source.extend(item[:-1])\n",
    "        target.extend(item[1:])\n",
    "        \n",
    "    max_len = int(round(np.array([len(x.split(' ')) for x in all_sentences]).mean()))\n",
    "    \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_sentences)\n",
    "    source = tokenizer.texts_to_sequences(source)\n",
    "    target = tokenizer.texts_to_sequences(target)\n",
    "    \n",
    "    assert len(source) == len(target)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        source[i] = np.hstack(([start_token], np.add(source[i][:max_len], 3), [end_token]))\n",
    "        target[i] = np.hstack(([start_token], np.add(target[i][:max_len], 3), [end_token]))    \n",
    "            \n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(source, maxlen=max_len + 2, padding = 'post')\n",
    "    labels = tf.keras.preprocessing.sequence.pad_sequences(target, maxlen=max_len + 2, padding = 'post')\n",
    "    \n",
    "    t2i, i2t = make_vocab(tokenizer.word_index, pad_token, start_token, end_token, unk_token)\n",
    "    \n",
    "    \n",
    "    return inputs, labels, t2i, i2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(inputs, labels):\n",
    "    \n",
    "    encoder_inputs = inputs[:,1:]\n",
    "    decoder_inputs = labels[:, :-1]\n",
    "    decoder_outputs = labels[:, 1:]\n",
    "    \n",
    "    return encoder_inputs, decoder_inputs, decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losd_numpy_array(path):\n",
    "    return np.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(sentence_len, model_dim, dtype = tf.float32):\n",
    "    '''\n",
    "    Positional Encoding\n",
    "    paper: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    arg\n",
    "        sentence_len: integer.\n",
    "        model_dim: integer. dimension used by model\n",
    "        dtype: tensorflow data type Default is 'tf.float32'\n",
    "    \n",
    "    return\n",
    "        positional_2d: shape is [sentence_len, model_dim]\n",
    "    '''\n",
    "    \n",
    "    positional_1d = np.array([pos/10000**(2*i/model_dim) for pos in range(sentence_len) for i in range(model_dim)])\n",
    "    # for even number\n",
    "    positional_1d[::2] = np.sin(positional_1d[::2])\n",
    "    # for odd number\n",
    "    positional_1d[1::2] = np.cos(positional_1d[1::2])\n",
    "    \n",
    "    positional_2d = positional_1d.reshape([sentence_len, model_dim])\n",
    "    positional_2d = tf.cast(positional_2d, dtype)\n",
    "    \n",
    "    \n",
    "    return positional_2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(queries, \n",
    "                            keys,\n",
    "                            values,\n",
    "                            k_dim,\n",
    "                            v_dim,\n",
    "                            num_heads = 8,\n",
    "                            num_units = None, \n",
    "                            drop_out = 0, \n",
    "                            is_train = True, \n",
    "                            scope = \"multi_head_attention\", \n",
    "                            reuse = False, \n",
    "                            masked = False):\n",
    "    \n",
    "    '''\n",
    "    Multi head Attention\n",
    "    \n",
    "    Input\n",
    "    queries => [BS x sentence len x d_model]\n",
    "    keys => [BS x sentence len x d_model]\n",
    "    value => [BS x sentence len x d_moel]\n",
    "    num_heads => number of head\n",
    "    k_dim => dimension of k\n",
    "    v_dim => dimension of v\n",
    "    '''\n",
    "    \n",
    "    assert k_dim % num_heads == 0, 'Dimension can\\'t devided by number of head' \n",
    "    assert v_dim % num_heads == 0, 'Dimension can\\'t devided by number of head' \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(scope, reuse = reuse):\n",
    "        \n",
    "        d_model = queries.shape.as_list()[-1]\n",
    "        batch_size = queries.shape.as_list()[0]\n",
    "        sentence_len = queries.shape.as_list()[1]\n",
    "        \n",
    "        '''\n",
    "        Q => [ BS x sentence len x k_dim ]\n",
    "        K => [ BS x sentence len x k_dim ]\n",
    "        V => [ BS x sentence len x v_dim ]\n",
    "        '''\n",
    "        Q = tf.layers.dense(inputs = queries, units = k_dim)\n",
    "        K = tf.layers.dense(inputs = keys, units = k_dim)\n",
    "        V = tf.layers.dense(inputs = values, units = v_dim)\n",
    "        \n",
    "        '''\n",
    "        Masking 추가 필요\n",
    "        '''\n",
    "        \n",
    "        k_dim_i = k_dim // num_heads \n",
    "        v_dim_i = v_dim // num_heads\n",
    "        \n",
    "        Q_i = tf.stack(tf.split(value = Q, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (k_dim/num_head)]\n",
    "        K_i = tf.stack(tf.split(value = K, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (k_dim/num_head)]\n",
    "        V_i = tf.stack(tf.split(value = V, num_or_size_splits = num_heads, axis = -1)) # [num_head x BS x sentence len x (v_dim/num_head)]\n",
    "        \n",
    "        Q_K = tf.matmul(Q_i, tf.transpose(K_i, [0,1,3,2])) / (K_i.shape.as_list()[-1] ** 0.5) # [num_head x BS x sentence_len x sentence_len]\n",
    "\n",
    "        \n",
    "        #if masked:\n",
    "        #    output_like_softmax = tf.ones_like(Q_K[0, 0, :, :])\n",
    "        #    lower_triangle = tf.linalg.LinearOperatorLowerTriangular(output_like_softmax).to_dense()\n",
    "        #    masks = tf.tile(tf.expand_dims(tf.expand_dims(lower_triangle, 0), 0), [Q_K.shape.as_list()[0], Q_K.shape.as_list()[1], 1, 1])\n",
    "        #    pad = tf.ones_like(masks) * -(2**32 +1)\n",
    "        #    Q_K = tf.where(tf.equal(masks, 0), pad, Q_K)\n",
    "        \n",
    "        if masked:\n",
    "            masks = tf.linalg.LinearOperatorLowerTriangular(Q_K).to_dense()\n",
    "            pad = tf.ones_like(masks) * -(2**32 +1)\n",
    "            Q_K = tf.where(tf.equal(masks, 0), pad, Q_K)\n",
    "        \n",
    "        Q_K_softmax = tf.nn.softmax(Q_K) # [num_head x BS x sentence_len x sentence_len]\n",
    "        outputs = tf.matmul(Q_K_softmax, V_i) # [num_head x BS x sentence len x (v_dim/num_head)]\n",
    "            \n",
    "        outputs = tf.transpose(outputs,[1,2,0,3])\n",
    "        shape_outputs = outputs.get_shape().as_list() # [?, 7, 8, 64]\n",
    "        outputs = tf.reshape(outputs, shape = [-1, shape_outputs[1], shape_outputs[2] * shape_outputs[3]])\n",
    "        outputs = tf.layers.dense(inputs = outputs, units = d_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inputs, \n",
    "              epsilon = 1e-8,\n",
    "              scope=\"ln\",\n",
    "              reuse=None):\n",
    "    '''Applies layer normalization.\n",
    "    \n",
    "    Args:\n",
    "      inputs: A tensor with 2 or more dimensions, where the first dimension has\n",
    "        `batch_size`.\n",
    "      epsilon: A floating number. A very small number for preventing ZeroDivision Error.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
    "        by the same name.\n",
    "      \n",
    "    Returns:\n",
    "      A tensor with the same shape and data dtype as `inputs`.\n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        inputs_shape = inputs.get_shape()\n",
    "        params_shape = inputs_shape[-1:]\n",
    "    \n",
    "        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "        beta= tf.Variable(tf.zeros(params_shape))\n",
    "        gamma = tf.Variable(tf.ones(params_shape))\n",
    "        normalized = (inputs - mean) / ( (variance + epsilon) ** (.5) )\n",
    "        outputs = gamma * normalized + beta\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_normalize(x, f_x, scope = \"add_and_normalize\", reuse = tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(scope, reuse = reuse):\n",
    "        result = normalize(tf.add(x,f_x), reuse=reuse)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_layer(inputs, dense1, dense2, scope = \"feed_forward_layer\", reuse = False):\n",
    "\n",
    "    with tf.variable_scope(scope, reuse = reuse):\n",
    "        x = dense1(inputs)\n",
    "        out = dense2(x)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_layer(inputs, num_filter1, num_filter2, scope = \"conv_1d_layer\", reuse = False):\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse = reuse):\n",
    "        x = tf.keras.layers.Conv1D(filters = num_filter1, kernel_size = 1, activation = tf.nn.relu)(inputs)\n",
    "        out = tf.keras.layers.Conv1D(filters = num_filter2, kernel_size = 2)(inputs)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_layers = 2,\n",
    "                 k_dim = 512,\n",
    "                 v_dim = 512,\n",
    "                 num_heads = 8,\n",
    "                 w1_dim = 512 * 4,\n",
    "                 w2_dim = 512,\n",
    "                 dropout_rate = 0.2,\n",
    "                 use_conv = False):\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.k_dim = k_dim\n",
    "        self.v_dim = v_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_conv = use_conv\n",
    "        self.feed1 = tf.keras.layers.Dense(units = w1_dim, activation = tf.nn.relu)\n",
    "        self.feed2 = tf.keras.layers.Dense(units = w2_dim)\n",
    "        \n",
    "    def build(self, encoder_inputs, reuse = False):\n",
    "        \n",
    "        with tf.variable_scope('encoder', reuse = reuse):\n",
    "            \n",
    "            model_dim = encoder_inputs.shape.as_list()[2]\n",
    "            encoder_inputs = tf.keras.layers.Dropout(rate = self.dropout_rate)(encoder_inputs)\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                with tf.variable_scope(\"encoder_{}-layer\".format(i)):\n",
    "                    encoder_inputs_attention = multi_head_attention(queries = encoder_inputs,\n",
    "                                                                     keys = encoder_inputs,\n",
    "                                                                     values =  encoder_inputs,\n",
    "                                                                     k_dim = self.k_dim,\n",
    "                                                                     v_dim = self.v_dim,\n",
    "                                                                     num_heads = self.num_heads,\n",
    "                                                                     drop_out = self.dropout_rate,\n",
    "                                                                     masked = False)\n",
    "                    encoder_inputs = add_and_normalize(x = encoder_inputs, f_x = encoder_inputs_attention)\n",
    "\n",
    "                    if self.use_conv:\n",
    "                        encoder_inputs_forward = conv_1d_layer(inputs = encoder_inputs,\n",
    "                                                               num_filter1 = self.w1_dim,\n",
    "                                                               num_filter2 = self.w2_dim)\n",
    "                    else:\n",
    "                        encoder_inputs_forward = feed_forward_layer(inputs = encoder_inputs, dense1 = self.feed1, dense2 = self.feed2)\n",
    "                    \n",
    "                    encoder_inputs = add_and_normalize(x = encoder_inputs, f_x = encoder_inputs_forward)\n",
    "            \n",
    "            encoder_outputs = encoder_inputs\n",
    "            \n",
    "        return encoder_outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_layers = 2,\n",
    "                 k_dim = 512,\n",
    "                 v_dim = 512,\n",
    "                 num_heads = 8,\n",
    "                 w1_dim = 512 * 4,\n",
    "                 w2_dim = 512,\n",
    "                 dropout_rate = 0.2,\n",
    "                 use_conv = False):\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.k_dim = k_dim\n",
    "        self.v_dim = v_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_conv = use_conv\n",
    "        \n",
    "        self.feed1 = tf.keras.layers.Dense(units = w1_dim, activation=tf.nn.relu)\n",
    "        self.feed2 = tf.keras.layers.Dense(units = w2_dim)\n",
    "        \n",
    "\n",
    "    def build(self, encoder_outputs, decoder_inputs, reuse = False):\n",
    "        \n",
    "        with tf.variable_scope('decoder', reuse = reuse):\n",
    "            \n",
    "            model_dim = decoder_inputs.shape.as_list()[2]\n",
    "\n",
    "            decoder_inputs = tf.keras.layers.Dropout(rate = self.dropout_rate)(decoder_inputs)\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                with tf.variable_scope(\"decoder_{}-layer\".format(i)):\n",
    "\n",
    "\n",
    "                    decoder_self_attention = multi_head_attention(queries = decoder_inputs,\n",
    "                                                                     keys = decoder_inputs,\n",
    "                                                                     values =  decoder_inputs,\n",
    "                                                                     k_dim = self.k_dim,\n",
    "                                                                     v_dim = self.v_dim,\n",
    "                                                                     num_heads = self.num_heads,\n",
    "                                                                     drop_out = self.dropout_rate,\n",
    "                                                                     masked = True, reuse = tf.AUTO_REUSE)\n",
    "\n",
    "                    decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_self_attention)\n",
    "\n",
    "                    decoder_attention = multi_head_attention(queries = encoder_outputs,\n",
    "                                                                keys = encoder_outputs,\n",
    "                                                                values = decoder_inputs,\n",
    "                                                                k_dim = self.k_dim,\n",
    "                                                                v_dim = self.v_dim,\n",
    "                                                                num_heads = self.num_heads,\n",
    "                                                                drop_out = self.dropout_rate,\n",
    "                                                                masked = False, reuse = tf.AUTO_REUSE)\n",
    "\n",
    "                    decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_attention)\n",
    "\n",
    "                    if self.use_conv:\n",
    "                        decoder_inputs_forward = conv_1d_layer(inputs = decoder_inputs,\n",
    "                                                               num_filter1 = self.w1_dim,\n",
    "                                                               num_filter2 = self.w2_dim)\n",
    "                    else:\n",
    "                        decoder_inputs_forward = feed_forward_layer(inputs = decoder_inputs,\n",
    "                                                                    dense1 = self.feed1,\n",
    "                                                                    dense2= self.feed2,\n",
    "                                                                    reuse = reuse)\n",
    "\n",
    "                    decoder_inputs = add_and_normalize(x = decoder_inputs, f_x = decoder_inputs_forward)\n",
    "            \n",
    "            decoder_outputs = decoder_inputs\n",
    "        \n",
    "        return decoder_outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_encoder(encoder_inputs):\n",
    "    encoder = Encoder(num_layers = 2,\n",
    "                 k_dim = 512,\n",
    "                 v_dim = 512,\n",
    "                 num_heads = 8,\n",
    "                 w1_dim = 512 * 4,\n",
    "                 w2_dim = 512,\n",
    "                 dropout_rate = 0.2,\n",
    "                 use_conv = False)\n",
    "    return encoder.build(encoder_inputs=encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder(encoder_outputs, decoder_inputs, reuse = False):\n",
    "    decoder = Decoder(num_layers = 2,\n",
    "                 k_dim = 512,\n",
    "                 v_dim = 512,\n",
    "                 num_heads = 8,\n",
    "                 w1_dim = 512 * 4,\n",
    "                 w2_dim = 512,\n",
    "                 dropout_rate = 0.2,\n",
    "                 use_conv = False)\n",
    "    return decoder.build(encoder_outputs = encoder_outputs, decoder_inputs = decoder_inputs, reuse = reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, mode, params):\n",
    "    \n",
    "    embedding_matrix = params['embedding_matrix']\n",
    "    VOCAB_SIZE = params['vocab_size']\n",
    "    EMBEDDING_DIMENSION = params['embedding_dimension']\n",
    "    NUM_LAYERS = params['num_layers']\n",
    "    K_DIM = params['k_dim']\n",
    "    V_DIM = params['v_dim']\n",
    "    NUM_HEADS = params['num_heads']\n",
    "    W1_DIM = params['w1_dim']\n",
    "    W2_DIM = params['w2_dim']\n",
    "    DROPOUT_RATE = params['dropout_rate']\n",
    "    USE_CONV = params['use_conv']\n",
    "    SENTENCE_LEN = params['sentence_len']\n",
    "    LEARNING_RATE = params['learning_rate']\n",
    "    \n",
    "    \n",
    "    encoder_inputs = features['encoder_inputs']\n",
    "    decoder_inputs = features['decoder_inputs']\n",
    "    labels = features['decoder_labels']\n",
    "    \n",
    "    \n",
    "    \n",
    "    batch_size = tf.shape(encoder_inputs)[0]\n",
    "    \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    # embedding matrix 가중치 나눶주기\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "    \n",
    "    with tf.variable_scope('linear', reuse = tf.AUTO_REUSE):\n",
    "        linear_transformation = tf.keras.layers.Dense(units = VOCAB_SIZE, kernel_regularizer=regularizer)\n",
    "    \n",
    "    if embedding_matrix is None:\n",
    "        \n",
    "        with tf.variable_scope('embedding'):        \n",
    "            embedding_matrix = tf.get_variable(name = 'embedding_matrix',\n",
    "                                               dtype=tf.float32,\n",
    "                                               shape=[VOCAB_SIZE - 1, EMBEDDING_DIMENSION],\n",
    "                                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "            embedding_matrix = tf.concat((tf.zeros(shape = [1,EMBEDDING_DIMENSION], dtype=tf.float32), embedding_matrix), axis = 0)\n",
    "    \n",
    "    \n",
    "\n",
    "    encoder_inputs = tf.nn.embedding_lookup(ids = encoder_inputs, params = embedding_matrix)\n",
    "    decoder_inputs = tf.nn.embedding_lookup(ids = decoder_inputs, params = embedding_matrix)\n",
    "\n",
    "\n",
    "    position_inputs = tf.tile(tf.expand_dims(positional_encoding(sentence_len = SENTENCE_LEN,\n",
    "                                                                 model_dim = EMBEDDING_DIMENSION,\n",
    "                                                                 dtype = tf.float32), 0), [batch_size, 1, 1])\n",
    "    encoder_inputs = tf.add(encoder_inputs, position_inputs)\n",
    "    decoder_inputs = tf.add(decoder_inputs, position_inputs)\n",
    "\n",
    "    \n",
    "    decoder = Decoder(num_layers = 2,\n",
    "                     k_dim = 512,\n",
    "                     v_dim = 512,\n",
    "                     num_heads = 8,\n",
    "                     w1_dim = 512 * 4,\n",
    "                     w2_dim = 512,\n",
    "                     dropout_rate = 0.2,\n",
    "                     use_conv = False)\n",
    "\n",
    "    encoder = Encoder(num_layers = 2,\n",
    "                      k_dim = 512,\n",
    "                      v_dim = 512,\n",
    "                      num_heads = 8,\n",
    "                      w1_dim = 512 * 4,\n",
    "                      w2_dim = 512,\n",
    "                      dropout_rate = 0.2,\n",
    "                      use_conv = False)\n",
    "    \n",
    "    #encoder_outputs = make_encoder(encoder_inputs = encoder_inputs)\n",
    "    #decoder_outputs = make_decoder(encoder_outputs = encoder_outputs, decoder_inputs = decoder_inputs)\n",
    "\n",
    "\n",
    "    #LInear Transformation 으로 embedding matrix 사용 시\n",
    "    #embedding_matrix_tile = tf.tile(tf.expand_dims(embedding_matrix, 0), [batch_size, 1, 1])\n",
    "    #linear_outputs = tf.matmul(decoder_outputs, embedding_matrix_tile, transpose_b = True) # [BS x sen_len x vocab_size]\n",
    "    \n",
    "    encoder_outputs = encoder.build(encoder_inputs = encoder_inputs)\n",
    "    decoder_outputs = decoder.build(encoder_outputs = encoder_outputs, decoder_inputs = decoder_inputs)\n",
    "    \n",
    "    \n",
    "    linear_outputs = linear_transformation(decoder_outputs)\n",
    "    prob_outputs = tf.nn.softmax(linear_outputs)\n",
    "    token_outputs = tf.argmax(prob_outputs, axis = -1)\n",
    "    \n",
    "    if PREDICT:\n",
    "        decoder_inputs = make_pred_decoder_inputs(input_token = features['decoder_inputs'], output_token = token_outputs, idx = 1)\n",
    "        \n",
    "             \n",
    "        for i in range(1, SENTENCE_LEN):\n",
    "            print(i)\n",
    "            decoder_embed = tf.nn.embedding_lookup(ids = decoder_inputs, params = embedding_matrix)\n",
    "            decoder_embed = tf.add(decoder_embed, position_inputs)\n",
    "            decoder_outputs = decoder.build(encoder_outputs = encoder_outputs, decoder_inputs = decoder_embed, reuse = True)\n",
    "            \n",
    "            token_outputs = linear_transformation(decoder_outputs)\n",
    "            token_outputs = tf.argmax(prob_outputs, axis = -1)\n",
    "            if i != SENTENCE_LEN -1:\n",
    "                decoder_inputs = make_pred_decoder_inputs(input_token = decoder_inputs, output_token = token_outputs, idx = i)\n",
    "\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = token_outputs)\n",
    "\n",
    "    mask_zero = 1 - tf.cast(tf.equal(labels, 0),dtype=tf.float32)\n",
    "    mask_end = 1 - tf.cast(tf.equal(labels, 2), dtype=tf.float32)\n",
    "    labels_one_hot = tf.one_hot(indices = labels, depth = VOCAB_SIZE, dtype = tf.float32) # [BS, senxlen, vocab_size]\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels = labels_one_hot, logits = linear_outputs)\n",
    "    loss = loss * mask_zero\n",
    "    loss = loss * mask_end\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "        train_optimizer = optimizer.minimize(loss, global_step  = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_decoder_inputs(input_token, output_token, idx):\n",
    "    \n",
    "    '''\n",
    "    idx: 1->6\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # input_token, output_token, idx\n",
    "    # [1,0,0,0,0,0,0], X, [1 , 32, X, X, X, X]\n",
    "    # [1,32,0,0,0,0,0], [1, 32, 77, X, X, X, X], 1\n",
    "    # [1,32,77,0,0,0,0], []\n",
    "    # [1,32,77,5,0,0,0]\n",
    "    # [1,32,77,5,39,0,0]\n",
    "    # [1,32,77,5,39,8,0]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    batch_size = input_token.get_shape()[0]\n",
    "    max_len = input_token.get_shape()[1]\n",
    "    \n",
    "    left = tf.slice(input_token, [0,0], [-1, idx])\n",
    "    right = tf.slice(output_token, [0, idx], [-1, 1])\n",
    "    right = tf.cast(right, tf.int32)\n",
    "    zero = tf.zeros_like(input_token)\n",
    "    zero_slice = tf.slice(zero, [0, idx + 1], [-1, max_len - (idx + 1)])\n",
    "    \n",
    "    new_input = tf.concat((left,right,zero_slice), axis=1)\n",
    "    \n",
    "    return new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './poem_data.json'\n",
    "\n",
    "inputs, labels, t2i, i2t = load_data(PATH)\n",
    "encoder_inputs, decoder_inputs, decoder_labels = prepare_data(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764, 7)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_fn(X, Y, Z):\n",
    "    features = {'encoder_inputs': X, 'decoder_inputs': Y, 'decoder_labels': Z}\n",
    "    return features\n",
    "\n",
    "def train_data():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((encoder_inputs, decoder_inputs, decoder_labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(encoder_inputs))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCH)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './check_point5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000217D0A1AA20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = './check_point5'\n",
    "params = {'embedding_matrix': None,\n",
    "          'vocab_size': len(i2t),\n",
    "          'embedding_dimension': 512,\n",
    "          'num_layers': 2,\n",
    "          'k_dim': 512,\n",
    "          'v_dim': 512,\n",
    "          'num_heads': 8,\n",
    "          'w1_dim': None,\n",
    "          'w2_dim': None,\n",
    "          'dropout_rate': 0.2,\n",
    "          'use_conv': False,\n",
    "          'sentence_len': encoder_inputs.shape[1],\n",
    "          'learning_rate': 0.001}\n",
    "\n",
    "est = tf.estimator.Estimator(model, model_dir=MODEL_DIR, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "est.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_encoder_inputs, pred_decoder_inputs, pred_decoder_outputs = np.array([encoder_inputs[21]]), np.array([[1,0,0,0,0,0,0]]), np.array([decoder_inputs[21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_input_fn():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((pred_encoder_inputs, pred_decoder_inputs, pred_decoder_outputs))\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict = est.predict(input_fn = pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
